{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p8qrL9rVZE8r"
   },
   "outputs": [],
   "source": [
    "\"\"\"!pip install transformers\n",
    "!pip install pydub\n",
    "!pip install -U openai-whisper\n",
    "!pip install ffmpeg-python\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28Tefn8fZ3Px",
    "outputId": "c729aa64-7f9f-4863-c139-105b56ed931a"
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-W6oxfHNaDY5",
    "outputId": "3de0fc0a-38ea-4c05-894d-391cecff0ff5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install setuptools-rust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#conda install -c conda-forge google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install Js2Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wavio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sounddevice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "X6JEAD4vLeOU"
   },
   "outputs": [],
   "source": [
    "# audio = get_audio()\n",
    "# audio_array = audio_segment_to_ndarray(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zJsmNMVAu2pV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "def numpy_array_to_mp3(audio_array, output_file_path, sample_rate=44100):\n",
    "\n",
    "    audio_array = audio_array / np.max(np.abs(audio_array))\n",
    "\n",
    "    # Converting the numpy array to an audio file\n",
    "    sf.write(output_file_path, audio_array, sample_rate, format='wav')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HtVOfYd5e_nk"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "model0 = whisper.load_model(\"medium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwvhptHlg5Sa",
    "outputId": "bcfdf7a7-738b-4d55-f6ff-b1056b9f889c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install transformers --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip show transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ANACONDA\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!\"C:\\\\ANACONDA\\\\python.exe\" -m pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v-jURlXF4M-w"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "dialouge = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q torchaudio omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "complicated-receiver"
   },
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from pprint import pprint\n",
    "from omegaconf import OmegaConf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
    "                               'latest_silero_models.yml',\n",
    "                               progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14f49758",
    "outputId": "9d1872c7-67fb-4b24-b5b6-025766503dc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Muhammad Ali Khan/.cache\\torch\\hub\\snakers4_silero-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "language = 'en'\n",
    "model_id = 'v3_en'\n",
    "device = torch.device('cuda')\n",
    "\n",
    "modelstr, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                     model='silero_tts',\n",
    "                                     language=language,\n",
    "                                     speaker=model_id)\n",
    "#modelstr = torch.modelstr('cuda')  # gpu or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Ali Khan\\Desktop\\LALA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [25/Jul/2023 11:45:01] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jul/2023 11:45:01] \"GET /staticFiles/index2.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Jul/2023 11:45:01] \"GET /staticFiles/index2.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Jul/2023 11:45:01] \"GET /staticFiles/style.css HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Recieved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA\\Lib\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello sir.\n",
      "Hello, sir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Jul/2023 11:45:46] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template, send_file\n",
    "import os\n",
    "import soundfile as sf\n",
    "import io\n",
    "import base64\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "app = Flask(__name__, template_folder='templateFiles', static_folder='staticFiles')\n",
    "\n",
    "# Replace this function with your ML model prediction logic\n",
    "def ml_model_prediction(audio_blob):\n",
    "    # Simulate ML model prediction - replace this with actual ML model interaction\n",
    "    \n",
    "    #convert_blob_to_wav(audio_blob, \"output.wav\")\n",
    "    audio_blob.seek(0)\n",
    "    \n",
    "    #audio_np = np.array(audio_data , dtype=np.float32\n",
    "    audio_data, _ = sf.read(io.BytesIO(audio_blob.read()))\n",
    "    sf.write(\"outputx.wav\", audio_data,48000 )\n",
    "    result = model0.transcribe(\"outputx.wav\")\n",
    "    print(result[\"text\"])\n",
    "    for step in range(1):\n",
    "        new_user_input_ids = tokenizer.encode(result[\"text\"] + tokenizer.eos_token, return_tensors='pt')\n",
    "        bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "        chat_history_ids = dialouge.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    f_text = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    print(f_text)\n",
    "  #.................................................\n",
    "    sample_rate = 48000\n",
    "    speaker = 'en_1'\n",
    "    put_accent=True\n",
    "    put_yo=True\n",
    "    example_text = f_text\n",
    "    audio = modelstr.apply_tts(text=example_text,\n",
    "                          speaker=speaker,\n",
    "                          sample_rate=sample_rate,\n",
    "                          put_accent=put_accent,\n",
    "                          put_yo=put_yo)\n",
    "\n",
    "    return audio\n",
    "    \n",
    "# Serve the index.html file\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('lala -2.html')\n",
    "\n",
    "# API endpoint for audio file upload and ML model prediction\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    print(\"Audio Recieved!\")\n",
    "    audio_blob = request.files['audio']\n",
    "\n",
    "    if not audio_blob:\n",
    "        return jsonify({'error': 'No audio file provided.'}), 400\n",
    "\n",
    "    # Perform prediction using ML model\n",
    "    predictions = ml_model_prediction(audio_blob)\n",
    "    \"\"\"audio_bytes = predictions.to('cpu').detach().numpy().tobytes()\n",
    "    audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')\n",
    "    response = {\n",
    "        'audio': audio_base64\n",
    "    }\n",
    "     return jsonify(response),200\"\"\"\n",
    "    sf.write(\"output2.wav\", predictions,48000 )\n",
    "    \n",
    "    audio_path = 'C:/Users/Muhammad Ali Khan/Desktop/LALA/output2.wav'\n",
    "    return send_file(audio_path, mimetype='output2/wav')\n",
    "   \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
