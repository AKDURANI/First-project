{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p8qrL9rVZE8r"
   },
   "outputs": [],
   "source": [
    "\"\"\"!pip install transformers\n",
    "!pip install pydub\n",
    "!pip install -U openai-whisper\n",
    "!pip install ffmpeg-python\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28Tefn8fZ3Px",
    "outputId": "c729aa64-7f9f-4863-c139-105b56ed931a"
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-W6oxfHNaDY5",
    "outputId": "3de0fc0a-38ea-4c05-894d-391cecff0ff5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install setuptools-rust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#conda install -c conda-forge google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install Js2Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wavio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sounddevice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "X6JEAD4vLeOU"
   },
   "outputs": [],
   "source": [
    "# audio = get_audio()\n",
    "# audio_array = audio_segment_to_ndarray(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\anaconda\\lib\\site-packages (2.0.1)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "                                              0.0/244.2 kB ? eta -:--:--\n",
      "     ------                                41.0/244.2 kB 653.6 kB/s eta 0:00:01\n",
      "     ---------                             61.4/244.2 kB 812.7 kB/s eta 0:00:01\n",
      "     ----------------                     112.6/244.2 kB 930.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 244.2/244.2 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torchaudio in c:\\anaconda\\lib\\site-packages (2.0.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "                                              0.0/486.2 kB ? eta -:--:--\n",
      "     -----------------                     225.3/486.2 kB 13.4 MB/s eta 0:00:01\n",
      "     -----------------                     225.3/486.2 kB 13.4 MB/s eta 0:00:01\n",
      "     ----------------------------           368.6/486.2 kB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------         389.1/486.2 kB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------         389.1/486.2 kB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 486.2/486.2 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda\\lib\\site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: sympy in c:\\anaconda\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\anaconda\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda\\lib\\site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in c:\\anaconda\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\anaconda\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\anaconda\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\anaconda\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\anaconda\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\anaconda\\lib\\site-packages (from datasets) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\anaconda\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.2.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "                                              0.0/135.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 135.4/135.4 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\anaconda\\lib\\site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: aiohttp in c:\\anaconda\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\anaconda\\lib\\site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "                                              0.0/134.3 kB ? eta -:--:--\n",
      "     --------------------                    71.7/134.3 kB 3.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 134.3/134.3 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\anaconda\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, multiprocess, accelerate, datasets\n",
      "Successfully installed accelerate-0.21.0 datasets-2.13.1 multiprocess-0.70.14 xxhash-3.2.0\n",
      "Requirement already satisfied: transformers in c:\\anaconda\\lib\\site-packages (4.30.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "                                              0.0/7.4 MB ? eta -:--:--\n",
      "                                              0.0/7.4 MB ? eta -:--:--\n",
      "                                              0.1/7.4 MB 1.7 MB/s eta 0:00:05\n",
      "     -                                        0.2/7.4 MB 2.0 MB/s eta 0:00:04\n",
      "     -                                        0.4/7.4 MB 2.2 MB/s eta 0:00:04\n",
      "     ---                                      0.6/7.4 MB 2.7 MB/s eta 0:00:03\n",
      "     ---                                      0.7/7.4 MB 2.7 MB/s eta 0:00:03\n",
      "     ---                                      0.7/7.4 MB 2.7 MB/s eta 0:00:03\n",
      "     ----                                     0.7/7.4 MB 2.2 MB/s eta 0:00:03\n",
      "     ------                                   1.3/7.4 MB 3.2 MB/s eta 0:00:02\n",
      "     -------                                  1.4/7.4 MB 3.4 MB/s eta 0:00:02\n",
      "     ---------                                1.7/7.4 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------                               2.0/7.4 MB 3.8 MB/s eta 0:00:02\n",
      "     -----------                              2.2/7.4 MB 3.9 MB/s eta 0:00:02\n",
      "     -------------                            2.5/7.4 MB 4.2 MB/s eta 0:00:02\n",
      "     ---------------                          2.8/7.4 MB 4.4 MB/s eta 0:00:02\n",
      "     ----------------                         3.1/7.4 MB 4.6 MB/s eta 0:00:01\n",
      "     -------------------                      3.6/7.4 MB 4.8 MB/s eta 0:00:01\n",
      "     --------------------                     3.8/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------                    4.0/7.4 MB 4.8 MB/s eta 0:00:01\n",
      "     -----------------------                  4.3/7.4 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------                 4.4/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "     --------------------------               4.8/7.4 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------               4.8/7.4 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------               4.8/7.4 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------               4.9/7.4 MB 4.5 MB/s eta 0:00:01\n",
      "     ----------------------------             5.2/7.4 MB 4.5 MB/s eta 0:00:01\n",
      "     ----------------------------             5.3/7.4 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------           5.6/7.4 MB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------          5.8/7.4 MB 4.7 MB/s eta 0:00:01\n",
      "     ---------------------------------        6.2/7.4 MB 4.8 MB/s eta 0:00:01\n",
      "     -----------------------------------      6.5/7.4 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------     6.8/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.0/7.4 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.4/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.4/7.4 MB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\anaconda\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\anaconda\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\anaconda\\lib\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.2\n",
      "    Uninstalling transformers-4.30.2:\n",
      "      Successfully uninstalled transformers-4.30.2\n",
      "Successfully installed transformers-4.31.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch accelerate torchaudio datasets\n",
    "#!pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to c:\\users\\muhammad ali khan\\appdata\\local\\temp\\pip-req-build-v9f22j0j\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit c9a82be592ca305180a7ab6a36e884bca1d426b8\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from transformers==4.32.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\anaconda\\lib\\site-packages (from transformers==4.32.0.dev0) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda\\lib\\site-packages (from transformers==4.32.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from transformers==4.32.0.dev0) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda\\lib\\site-packages (from transformers==4.32.0.dev0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda\\lib\\site-packages (from transformers==4.32.0.dev0) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from transformers==4.32.0.dev0) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\anaconda\\lib\\site-packages (from transformers==4.32.0.dev0) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\anaconda\\lib\\site-packages (from transformers==4.32.0.dev0) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda\\lib\\site-packages (from transformers==4.32.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (2023.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (4.6.3)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers==4.32.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests->transformers==4.32.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->transformers==4.32.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->transformers==4.32.0.dev0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->transformers==4.32.0.dev0) (2023.5.7)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml): started\n",
      "  Building wheel for transformers (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.32.0.dev0-py3-none-any.whl size=7406088 sha256=d4d14b9093bca6eeec79e9bad2494b1d4ac63007f379d0a0bbee0ef7c5b74a95\n",
      "  Stored in directory: C:\\Users\\Muhammad Ali Khan\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-bnq8c__f\\wheels\\32\\4b\\78\\f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n",
      "Successfully installed transformers-4.32.0.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git 'C:\\Users\\Muhammad Ali Khan\\AppData\\Local\\Temp\\pip-req-build-v9f22j0j'\n"
     ]
    }
   ],
   "source": [
    "#pip install git+https://github.com/huggingface/transformers.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m model7 \u001b[38;5;241m=\u001b[39m Wav2Vec2ForCTC\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#model7 = model7.to('cuda')\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model7  \u001b[38;5;241m=\u001b[39m model7\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mC:\\ANACONDA\\Lib\\site-packages\\transformers\\modeling_utils.py:1904\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1899\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1900\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.to` is not supported for `4-bit` or `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1901\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1902\u001b[0m     )\n\u001b[0;32m   1903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1904\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ANACONDA\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32mC:\\ANACONDA\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ANACONDA\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 797 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mC:\\ANACONDA\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ANACONDA\\Lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mC:\\ANACONDA\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n",
      "File \u001b[1;32mC:\\ANACONDA\\Lib\\site-packages\\torch\\cuda\\__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, AutoProcessor\n",
    "import torch\n",
    "\n",
    "model_id = \"facebook/mms-1b-all\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model7 = Wav2Vec2ForCTC.from_pretrained(model_id)\n",
    "#model7 = model7.to('cuda')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\anaconda\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\anaconda\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\anaconda\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HtVOfYd5e_nk"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "model0 = whisper.load_model(\"small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwvhptHlg5Sa",
    "outputId": "bcfdf7a7-738b-4d55-f6ff-b1056b9f889c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install transformers --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip show transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ANACONDA\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!\"C:\\\\ANACONDA\\\\python.exe\" -m pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v-jURlXF4M-w"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "dialouge = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q torchaudio omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "complicated-receiver"
   },
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from pprint import pprint\n",
    "from omegaconf import OmegaConf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
    "                               'latest_silero_models.yml',\n",
    "                               progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14f49758",
    "outputId": "9d1872c7-67fb-4b24-b5b6-025766503dc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Muhammad Ali Khan/.cache\\torch\\hub\\snakers4_silero-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "language = 'en'\n",
    "model_id = 'v3_en'\n",
    "device = torch.device('cuda')\n",
    "\n",
    "modelstr, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                     model='silero_tts',\n",
    "                                     language=language,\n",
    "                                     speaker=model_id)\n",
    "#modelstr = torch.modelstr('cuda')  # gpu or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Ali Khan\\Desktop\\LALA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def calculate_execution_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Function '{func.__name__}' execution time: {execution_time:.6f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "from scipy.io import wavfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [26/Jul/2023 09:28:27] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Jul/2023 09:28:27] \"GET /staticFiles/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [26/Jul/2023 09:28:27] \"GET /staticFiles/index2.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [26/Jul/2023 09:28:27] \"GET /staticFiles/index2.js HTTP/1.1\" 304 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template, send_file\n",
    "import os\n",
    "import soundfile as sf\n",
    "import io\n",
    "import base64\n",
    "import scipy.signal as signal\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "app = Flask(__name__, template_folder='templateFiles', static_folder='staticFiles')\n",
    "\n",
    "# Replace this function with your ML model prediction logic\n",
    "def ml_model_prediction(audio_blob):\n",
    "    # Simulate ML model prediction - replace this with actual ML model interaction\n",
    "    \n",
    "    #convert_blob_to_wav(audio_blob, \"output.wav\")\n",
    "    audio_blob.seek(0)\n",
    "    \n",
    "    #audio_np = np.array(audio_data , dtype=np.float32\n",
    "    audio_data, _ = sf.read(io.BytesIO(audio_blob.read()))\n",
    "    sf.write(\"outputx.wav\", audio_data,48000 )\n",
    "    \n",
    "    #...................................................................\n",
    "    \n",
    "    # Read the audio file\n",
    "    sample_rate, audio_data = wav.read(\"outputx.wav\")\n",
    "\n",
    "    # Calculate the resampling ratio\n",
    "    resampling_ratio = float(16000) / 48000\n",
    "\n",
    "    # Perform the resampling\n",
    "    import scipy.signal as signal\n",
    "    resampled_audio_data = signal.resample(audio_data, int(len(audio_data) * resampling_ratio))\n",
    "    print(type(resampled_audio_data) )\n",
    "    # Save the resampled audio to the output file\n",
    "    wav.write(\"output.wav\", 16000, resampled_audio_data.astype(audio_data.dtype))\n",
    "    sample_rate = wav.read(\"output.wav\")\n",
    "    \n",
    "    #...................................................................\n",
    "    \n",
    "    # Read the WAV file using scipy.io.wavfile\n",
    "    sample_rate, audio_data = wavfile.read(\"output.wav\")\n",
    "\n",
    "    # Convert the audio data to a NumPy array\n",
    "    numpy_array = np.array(audio_data, dtype=np.float32)\n",
    "    \n",
    "    #...................................................................\n",
    "    \n",
    "    inputs = processor(numpy_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model7(**inputs).logits\n",
    "\n",
    "    ids = torch.argmax(outputs, dim=-1)[0]\n",
    "    transcription = processor.decode(ids)\n",
    "    print(type(transcription))\n",
    "    print(\"Transcription: \",transcription)\n",
    "    \n",
    "    #...................................................................\n",
    "    \n",
    "    for step in range(1):\n",
    "        new_user_input_ids = tokenizer.encode(transcription + tokenizer.eos_token, return_tensors='pt')\n",
    "        bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "        chat_history_ids = dialouge.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    f_text = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    #print(f_text)\n",
    "  #.................................................\n",
    "    sample_rate = 48000\n",
    "    speaker = 'en_1'\n",
    "    put_accent=True\n",
    "    put_yo=True\n",
    "    example_text = f_text\n",
    "    audio = modelstr.apply_tts(text=example_text,\n",
    "                          speaker=speaker,\n",
    "                          sample_rate=sample_rate,\n",
    "                          put_accent=put_accent,\n",
    "                          put_yo=put_yo)\n",
    "\n",
    "    return audio\n",
    "    \n",
    "# Serve the index.html file\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('lala -2.html')\n",
    "\n",
    "# API endpoint for audio file upload and ML model prediction\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    print(\"Audio Recieved!\")\n",
    "    audio_blob = request.files['audio']\n",
    "\n",
    "    if not audio_blob:\n",
    "        return jsonify({'error': 'No audio file provided.'}), 400\n",
    "\n",
    "    # Perform prediction using ML model\n",
    "    predictions = ml_model_prediction(audio_blob)\n",
    "    \"\"\"audio_bytes = predictions.to('cpu').detach().numpy().tobytes()\n",
    "    audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')\n",
    "    response = {\n",
    "        'audio': audio_base64\n",
    "    }\n",
    "     return jsonify(response),200\"\"\"\n",
    "    sf.write(\"output2.wav\", predictions,48000 )\n",
    "    \n",
    "    audio_path = 'C:/Users/Muhammad Ali Khan/Desktop/LALA/output2.wav'\n",
    "    return send_file(audio_path, mimetype='output2/wav')\n",
    "   \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
